{
	"projects": [
	  {
		"name": "Videography",
		"subdomain": "videography",
		"category": ["tangible", "networked", "participatory", "publication", "lead", "methods"],
		"subtitle": "videography",
		"abstract": "",
		"description": ["Annabella collects footage and edits her videos using Premier Pro."],
		"mainimg": "tapart.jpg",
		"video": ["False"],
		"images": ["tapart.jpg", "mario and luigi cropped.PNG", "draw 1.PNG", "dance actually.PNG", "robot marbles.PNG"],
		"published": ["True", "1"],
		"citations": [
		  ["Casey Lee Hunt, Kaiwen Sun, Zahra Dhuliawala, Fumi Tsukiyama, Iva Matkovic, Zachary Schwemler, Anastasia Wolf, Zihao Zhang, Allison Druin, Amanda Huynh, Daniel Leithinger, and Jason Yip. 2023. <span>Designing Together, Miles Apart: A Longitudinal Tabletop Telepresence Adventure in Online Co-Design with Children</span>. In Proceedings of the 22nd Annual ACM Interaction Design and Children Conference (IDC '23). Association for Computing Machinery, New York, NY, USA, 52–67.", "https://caseyhunt.github.io/assets/idc23-8_3.pdf", "View on ACM", "https://dl-acm-org.colorado.idm.oclc.org/doi/10.1145/3585088.3589359"]
		]
	  },
	  {
		"name": "Photography",
		"subdomain": "tactorbots",
		"category": ["tangible", "networked", "participatory", "toolkit", "shape_change", "publication", "award", "support"],
		"subtitle": "photography",
		"collaborators": ["Ran Zhou (Lead)", "Zachary Schwemler", "Aksha Baweja", "Harpreet Sareen", "Daniel Leithinger"],
		"abstract": "",
		"description": ["Psychological research has found that humans convey specific emotions (e.g., anger, fear, happiness) using social touch patterns, like squeezing a friend's arm when we are afraid. Emotional haptics, then, are an opportunity to create more enriching and intimate interactions with technology. However, designing emotional haptics systems requires a relatively high degree of technical skill. To overcome this challenge and make emotional haptics an accessible 'design canvas,' we created TactorBots. TactorBots is a haptic toolkit to create emotional robotic touch. It contains eight plug-and-play wearable tactor modules that render a series of social gestures with servo motors. The associated web GUI allows easy control, modification, and storage of tactile patterns to support fast prototyping. As a result, we remove the need for hardware design and programming, enabling designers to try out various tactile sensations, and create at the boundary between touch and emotion."],
		"mainimg": "tbots_cover.png",
		"video": ["True", "False"],
		"images": ["tbots_cover.png"],
		"video_url": "https://player.vimeo.com/video/798871223?h=dafa20ef89",
		"published": ["True", "1"],
		"citations": [
		  ["Ran Zhou, Zachary Schwemler, Akshay Baweja, Harpreet Sareen, Casey Lee Hunt, and Daniel Leithinger. 2023. <span>TactorBots: A Haptic Design Toolkit for Out-of-lab Exploration of Emotional Robotic Touch.</span> In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI '23). Association for Computing Machinery, New York, NY, USA, Article 370, 1–19.", "https://caseyhunt.github.io/assets/chi-23.pdf", "View on ACM", "https://dl-acm-org.colorado.idm.oclc.org/doi/abs/10.1145/3544548.3580799"]
		]
	  },
	  {
		"name": "Design",
		"subdomain": "ratio_and_proportion",
		"category": ["tangible", "participatory", "educational", "publication", "lead", "education"],
		"subtitle": "design",
		"collaborators": ["Chris Hill (Co-Lead)", "Sammie Crowder", "Brett Fielder", "Emily Moore", "Ann Eisenberg"],
		"abstract": "",
		"description": ["Sensory extensions enhance our awareness by transforming variations in stimuli normally undetectable by human senses into perceivable outputs. Similarly, interactive simulations for learning promote an understanding of abstract phenomena. Combining sensory extension devices with interactive simulations gives users the novel opportunity to connect their sensory experiences in the physical world to computer-simulated concepts. We explore this opportunity by designing a suite of wearable sensory extension devices that interface with a uniquely inclusive PhET Simulation, Ratio and Proportion. In this simulation, two hands can be moved on-screen to various values, representing different mathematical ratios. Users explore changing hand heights to find and maintain ratios through visual and auditory feedback. Our sensory extension devices translate force, distance, sound frequency, and magnetic field strength to quantitative values in order to control individual hands in the computer simulation. This paper describes the design of the devices and our analysis of feedback from 23 high-school aged youth who used our designs to interact with the Ratio and Proportion."],
		"mainimg": "sensoryextension_cover.jpg",
		"video": ["True", "True"],
		"images": ["sensoryextension_cover.jpg", "sensory_extension_render.png", "using_se.jpg"],
		"video_id": "naIZ2wla7WA",
		"published": ["True", "1"],
		"citations": [
		  ["Chris Hill, Casey Lee Hunt, Sammie Crowder, Brett Fiedler, Emily B. Moore, and Ann Eisenberg. 2023. <span>Investigating Sensory Extensions as Input for Interactive Simulations</span>. In Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction (TEI '23). Association for Computing Machinery, New York, NY, USA, Article 39, 1–7.", "https://caseyhunt.github.io/assets/tei-23.pdf", "View on ACM", "https://dl-acm-org.colorado.idm.oclc.org/doi/abs/10.1145/3569009.3573108"]
		]
	  }
	],
	"videos": [
	  {
		"title": "Fall Things to do in Boulder",
		"src": "portfolio/images/Video/OneDrive_1_12-4-2024/proof2-fallthingstodoaroundboulder.mp4"
	  },
	  {
		"title": "Wes Anderson",
		"src": "portfolio/images/Video/OneDrive_1_12-4-2024/proof3wesanderson.mp4"
	  }
	]
  }
  